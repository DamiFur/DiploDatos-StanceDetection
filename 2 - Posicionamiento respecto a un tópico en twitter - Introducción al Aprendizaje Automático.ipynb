{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente notebook se presentará la consigna a seguir para el tercer práctico del proyecto, correspondiente a la materia Introducción al Aprendizaje Automático. El objetivo consiste en explorar la aplicación de diferentes métodos de aprendizaje supervisado aprendidos en el curso, a través de experimentos reproducibles, y evaluando a su vez la conveniencia de uno u otro, así como la selección de diferentes hiperparámetros a partir del cálculo de las métricas pertinentes.\n",
    "\n",
    "En este caso, enfrentamos un problema de clasificación binario de posicionamiento respecto de un tópico. Para este práctico vamos a utilizar únicamente los datos etiquetados, que ya vienen divididos en train y test. Buscamos analizar distintos problemas que puedan surgir como el desbalanceo de clases\n",
    "\n",
    "\n",
    "## Organización\n",
    "\n",
    "El trabajo va a estar organizado en dos grandes secciones: preprocesamiento y aplicación de los clasificadores.\n",
    "\n",
    "#### Preprocesamiento\n",
    "En la parte de preprocesamiento lo que vamos a hacer va a ser:\n",
    "\n",
    "1 - Obtener el dataset\n",
    "\n",
    "2 - Tokenizar\n",
    "\n",
    "3 - Aplicar alguna curación\n",
    "\n",
    "4 - Balanceo de clases\n",
    "\n",
    "5 - Representar el texto como vector: CountVectorizer\n",
    "\n",
    "6 - Optativo: se puede representar el texto de otras maneras? Embeddings!\n",
    "\n",
    "#### Clasificadores\n",
    "\n",
    "1 - Perceptron\n",
    "\n",
    "2 - K-NN\n",
    "\n",
    "3 - Regresión Logística\n",
    "\n",
    "4 - Evaluación de los clasificadores\n",
    "\n",
    "5 - Optimización de Hiperparámetros\n",
    "\n",
    "Esto para los tres datasets CON y SIN balanceo de clases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.metrics import accuracy_score, f1_score, make_scorer, classification_report\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\", sep=',', encoding=\"latin1\").fillna(method=\"ffill\")\n",
    "test = pd.read_csv(\"test.csv\", sep=',', encoding=\"latin1\").fillna(method=\"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "abortion_train = train[train[\"Target\"] == \"Legalization of Abortion\"]\n",
    "abortion_test = test[test[\"Target\"] == \"Legalization of Abortion\"]\n",
    "\n",
    "climate_train = train[train[\"Target\"] == \"Climate Change is a Real Concern\"]\n",
    "climate_test = test[test[\"Target\"] == \"Climate Change is a Real Concern\"]\n",
    "\n",
    "feminism_train = train[train[\"Target\"] == \"Feminist Movement\"]\n",
    "feminism_test = test[test[\"Target\"] == \"Feminist Movement\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Target</th>\n",
       "      <th>Stance</th>\n",
       "      <th>Opinion Towards</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>We cant deny it, its really happening.  #SemST</td>\n",
       "      <td>Climate Change is a Real Concern</td>\n",
       "      <td>FAVOR</td>\n",
       "      <td>1.  The tweet explicitly expresses opinion abo...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>RT @cderworiz: Timelines are short. Strategy m...</td>\n",
       "      <td>Climate Change is a Real Concern</td>\n",
       "      <td>FAVOR</td>\n",
       "      <td>1.  The tweet explicitly expresses opinion abo...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>SO EXCITING! Meaningful climate change action ...</td>\n",
       "      <td>Climate Change is a Real Concern</td>\n",
       "      <td>FAVOR</td>\n",
       "      <td>1.  The tweet explicitly expresses opinion abo...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>Delivering good jobs for Albertans, maintainin...</td>\n",
       "      <td>Climate Change is a Real Concern</td>\n",
       "      <td>FAVOR</td>\n",
       "      <td>1.  The tweet explicitly expresses opinion abo...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>@davidswann says he wants carbon fund to be sp...</td>\n",
       "      <td>Climate Change is a Real Concern</td>\n",
       "      <td>FAVOR</td>\n",
       "      <td>3.  The tweet is not explicitly expressing opi...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Tweet  \\\n",
       "613     We cant deny it, its really happening.  #SemST   \n",
       "614  RT @cderworiz: Timelines are short. Strategy m...   \n",
       "615  SO EXCITING! Meaningful climate change action ...   \n",
       "616  Delivering good jobs for Albertans, maintainin...   \n",
       "617  @davidswann says he wants carbon fund to be sp...   \n",
       "\n",
       "                               Target Stance  \\\n",
       "613  Climate Change is a Real Concern  FAVOR   \n",
       "614  Climate Change is a Real Concern  FAVOR   \n",
       "615  Climate Change is a Real Concern  FAVOR   \n",
       "616  Climate Change is a Real Concern  FAVOR   \n",
       "617  Climate Change is a Real Concern  FAVOR   \n",
       "\n",
       "                                       Opinion Towards Sentiment  \n",
       "613  1.  The tweet explicitly expresses opinion abo...     other  \n",
       "614  1.  The tweet explicitly expresses opinion abo...       pos  \n",
       "615  1.  The tweet explicitly expresses opinion abo...       pos  \n",
       "616  1.  The tweet explicitly expresses opinion abo...       pos  \n",
       "617  3.  The tweet is not explicitly expressing opi...     other  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "climate_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sólo vamos a usar el tweet y el stance. Como encima ya tenemos dividido el corpus según el target, vamos a eliminar todas las columnas excepto tweet y stance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/damifur/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "abortion_train.drop(columns = [\"Target\", \"Opinion Towards\", \"Sentiment\"], inplace=True)\n",
    "abortion_test.drop(columns = [\"Target\", \"Opinion Towards\", \"Sentiment\"], inplace=True)\n",
    "\n",
    "climate_train.drop(columns = [\"Target\", \"Opinion Towards\", \"Sentiment\"], inplace=True)\n",
    "climate_test.drop(columns = [\"Target\", \"Opinion Towards\", \"Sentiment\"], inplace=True)\n",
    "\n",
    "feminism_train.drop(columns = [\"Target\", \"Opinion Towards\", \"Sentiment\"], inplace=True)\n",
    "feminism_test.drop(columns = [\"Target\", \"Opinion Towards\", \"Sentiment\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizamos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En principio como mínimo para realizar algún tipo de preprocesamiento y luego transformar nuestros datos en algo que pueda ser tomado como input por los clasificadores que vamos a probar necesitamos dividir nuestro tweet en formato string en una lista de palabras. La división requiere tomar decisiones sobre cómo tratar anomalías. En especial en twitter donde abundan las abreviaciones, errores ortográficos, puntuaciones raras, emojis, lo que se le ocurra al usuario.\n",
    "\n",
    "Hay muchas formas distintas de tokenizar y hay clasificadores que vienen con tokenizadores especiales incorporados al punto tal de que no pueden funcionar con otra tokenización (fastText y BERT por ejemplo separan la raíz de las parabras de sus prefijos y sufijos para poder relacionar palabras similares, como asociar todas las conjugaciones de un verbo a una misma raíz).\n",
    "\n",
    "Nosotros vamos a usar uno bien simple que tiene pocas funciones pero tiene algunas funciones pensadas especialmente para redes sociales, como por ejemplo detectar emojis o separar una palabra de sus signos de puntuación o asociar muchos signos de puntuación iguales y seguidos como si fueran uno solo (por ejemplo, !!!!!).\n",
    "\n",
    "https://www.nltk.org/api/nltk.tokenize.html\n",
    "\n",
    "Hay tres parámetros que pueden explorar leyendo la documentación (los que están escritos). Prueben ver qué pasa cuando cambian cada uno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TweetTokenizer(preserve_case=True, reduce_len=True, strip_handles=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@tooprettyclub',\n",
       " 'Are',\n",
       " 'you',\n",
       " 'OK',\n",
       " 'with',\n",
       " '#GOP',\n",
       " 'males',\n",
       " 'telling',\n",
       " 'you',\n",
       " 'what',\n",
       " 'you',\n",
       " 'can',\n",
       " 'and',\n",
       " \"can't\",\n",
       " 'do',\n",
       " 'with',\n",
       " 'your',\n",
       " 'own',\n",
       " 'body',\n",
       " '?']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(abortion_train[\"Tweet\"].iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El preprocesamiento para twitter requiere tomar varias decisiones. Recomiendo que vean un poco el dataset y piensen con qué palabras quieren trabajar y cuales quieren remover. Les dejo el esqueleto de una función de preprocesamiento que sólo tokeniza pero que puede tomar dos parámetros optativos para remover hashtags y números.\n",
    "\n",
    "#### Ejercicio 1\n",
    "\n",
    "Agregarle a la función de preprocesamiento que borre las urls (palabras que empiecen con http). Agregarle código para que agregue o saque texto de acuerdo con al menos un criterio propuesto por ustedes (menciones a los usuarios, caritas/emojis, puntuación)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocesar(text, keep_hashtags=True, remove_numbers=False):\n",
    "    toks = tokenizer.tokenize(text)\n",
    "\n",
    "    ret = []\n",
    "    for tok in toks:\n",
    "        if tok[0] == \"#\" and not keep_hashtags:\n",
    "            continue\n",
    "            \n",
    "        if tok.isnumeric() and remove_numbers:\n",
    "            continue\n",
    "        ret.append(tok)\n",
    "    return \" \".join(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/damifur/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Hacer esto para todos los datasets, train y test de los 3 tópicos\n",
    "abortion_train[\"Tweet\"] = abortion_train[\"Tweet\"].apply(lambda x: preprocesar(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Just laid down the law on abortion in my bioet...</td>\n",
       "      <td>AGAINST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>@tooprettyclub Are you OK with #GOP males tell...</td>\n",
       "      <td>FAVOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>If you don't want your kid , put it up for ado...</td>\n",
       "      <td>AGAINST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>@RedAlert - there should be a \" stigma \" to bu...</td>\n",
       "      <td>AGAINST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>But isn't that the problem then . Not enough f...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Tweet   Stance\n",
       "50  Just laid down the law on abortion in my bioet...  AGAINST\n",
       "51  @tooprettyclub Are you OK with #GOP males tell...    FAVOR\n",
       "52  If you don't want your kid , put it up for ado...  AGAINST\n",
       "53  @RedAlert - there should be a \" stigma \" to bu...  AGAINST\n",
       "54  But isn't that the problem then . Not enough f...     NONE"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abortion_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanceo de clases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el práctico anterior ya analizaron la distribución de las clases según cada target (tópico) del dataset. Queremos explorar la posibilidad de hacer un balanceo de clases. Para eso, analizamos tópico por tópico si esto es posible y las dificultades que tiene.\n",
    "\n",
    "Para el dataset de feminismo, tenemos dos versiones de train, una con correcciones y otra sin. En la versión con correcciones cambia el balanceo de las clases a algo más equitativo que en su version original. Por este motivo, vamos a descartar hacer un balanceo de clases en este dataset.\n",
    "\n",
    "Para el dataset de cambio climático tenemos un desbalanceo tan grande que, por ejemplo, sólo tenemos 11 ejemplos de la clase Against (el 6,5% del corpus). El problema que tiene una distribución tan desigual es que resulta dificil aplicar técnicas como el subsampling porque nos quedaríamos con 33 tweets de entrenamiento, o el oversampling porque para que las clases queden parejas, deberíamos repetir un mismo tweet muchas veces.\n",
    "\n",
    "Por lo tanto, nos queda el corpus de aborto:\n",
    "\n",
    "#### Ejercicio 2\n",
    "\n",
    "Hacer subsampling del corpus de aborto y guardarlo como un nuevo dataset. A partir de ahora, todos los experimentos que corran deberán correrlos además de para los tres corpus respectivos a cada tópico, también para este nuevo corpus de aborto con sus clases balanceadas. Luego vamos a comparar los resultados obtenidos con y sin balanceo de clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abortion_train_balanced = # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representación como vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los algoritmos de Machine Learning trabajan con espacios vectoriales. Entonces siempre que trabajemos con Procesamiento de Lenguaje Natural, como es nuestro caso, se plantea la cuestión de cómo representar texto con números. Hay muchas maneras de hacer esto y es un campo que sigue evolucionando con el tiempo. Una opción muy básica es asignarle a cada palabra que aparece en nuestro dataset un número según el orden en el que aparecen. Luego, una oración es un vector de índices de esas palabras. Pero el problema que tiene esto es que los algoritmos de Machine Learning también requieren que los vectores tengan una longitud fija, con lo cual hay que recortar la oración o agregarle ceros al final. Por eso un enfoque clásico para representar texto es el Bag Of Words: un vector de bits del tamaño de todo nuestro vocabulario que tiene un uno si la palabra está en la oración y un 0 si no está.\n",
    "\n",
    "https://es.wikipedia.org/wiki/Modelo_bolsa_de_palabras\n",
    "https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction\n",
    "\n",
    "En particular, vamos a usar la libreria CountVectorizer que implementa el Bag Of Words de manera esparsa (eficiente) y le agrega varios features que van a sernos muy útiles:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "\n",
    "En particular, vamos a usar los parámetros min_df y max_df que se corresponden con min y max document frequency. Ámbos toman valores entre 0 y 1 y estipulan el rango de frecuencia de aparición de una palabra dentro de un documento que vamos a aceptar. Es decir, si min_df es 0.005, todas las palabras que representen menos de un 0,5% de las palabras totales serán descartadas. Por el otro lado, si max_df es 0.35, todas las palabras que representen más de un 35% del total de palabras serán descartadas. Nos interesa descartar las palabras con demasiada frecuencia porque probablemente no tengan valor en términos de la entropía que aportan (es decir, no aportan información: pueden ser conectores, artículos, etc.) y las que tienen muy poca frecuencia porque pueden ser outliers, palabras demasiado específicas que no aportan a la tarea que queremos desarrollar.\n",
    "\n",
    "Las Bag Of Words, sin embargo, tienen un problema importante: no preservan el contexto y la relación semántica de las palabras entre sí. Este problema dio lugar a otros enfoques como los embeddings sobre los cuales les voy a dejar algunas cosas para que lean al final de manera optativa por si les da curiosidad. Incluso, luego de los embeddings, surgieron recientemente los contextualized embeddings que además de considerar la relación semántica, consideran el orden puntual dentro de la oración.\n",
    "\n",
    "Pero volviendo a las Bag Of Words, se puede hacer un pequeño \"truco\" para tener en cuenta, al menos parcialmente, algunas frases o expresiones con el orden en el que aparecen: el parámetro ngram_range calcula la frecuencia de ngramas. Resulta muy útil para descubrir frases o expresiones comunes (además de las palabras comunes). Además, en combinación con el parámetro \"analyzer\" se pueden usar como ngramas de palabras o de caracteres.\n",
    "\n",
    "#### Ejercicio 3\n",
    "\n",
    "Explorar los hiperparámetros de CountVectorizer. Ir modificando los valores de min_df, max_df y ngram-range. Observar cómo cambia el tamaño del vector.\n",
    "\n",
    "NOTA: Como el tamaño del vector (es decir, el vocabulario) debe ser igual para el entrenamiento como para el test, tenemos que vectorizar al mismo tiempo el dataset de train y de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train_abortion = abortion_train[\"Tweet\"]\n",
    "text_test_abortion = abortion_test[\"Tweet\"]\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    binary=True, min_df=0.0075, max_df=0.75, ngram_range=(1, 5),\n",
    "    #stop_words=stopwords.words('spanish')\n",
    ")\n",
    "\n",
    "X_abortion = vectorizer.fit_transform([*text_train, *text_test])\n",
    "\n",
    "VEC_train_abortion = X_abortion[:len(text_train)]\n",
    "VEC_test_abortion = X_abortion[len(text_train):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacer esto mismo para los otros tres datasets (Cambio climático, feminismo y el del aborto balanceado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VEC_train_climate = #TODO\n",
    "VEC_test_climate = #TODO\n",
    "\n",
    "VEC_train_feminism = #TODO\n",
    "VEC_test_feminism = #TODO\n",
    "\n",
    "VEC_train_abortion_balanced = #TODO\n",
    "VEC_test_abortion_balanced = #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXTRA: Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los embeddings de palabras son algo bastante nuevo en el campo del Procesamiento Del Lenguaje Natural (ultimos 10 años) pero fueron algo totalmente revolucionario que cambio absolutamente la disciplina. Desde que aparecieron las primeras versiones de embeddings (word2vec, glove, varias otras) surgieron muchas versiones distintas hechas con diversos algoritmos y técnicas. Pero todos tienen algo en común: tratan de captar la semántica de una palabra representandola con un vector (un número) que se calcula en base a los valores de las palabras que aparecen en el contexto de esa palabra. O sea, para cada palabra se calcula de manera iterativa un valor sobre la base de qué palabras aparecen antes y después en miles y miles de textos que se usan para entrenar los embeddings. Esos valores luego se exportan y se usan como representación de las palabras.\n",
    "\n",
    "No es del alcance de este trabajo práctico meterse en este tema, que correspondería más a un curso introductorio de Procesamiento del Lenguaje Natural y ya no a Machine Learning, pero me pareció interesante comentarselos como una alternativa (muy muy) frecuente frente al problema de decidir como representar texto con números.\n",
    "\n",
    "Si les interesa y quieren leer/investigar más al respecto, aca hay una clase del curso de PLN de Standford:\n",
    "https://www.youtube.com/watch?v=ERibwqs9p38&list=PL3FW7Lu3i5Jsnh1rnUwq_TcylNr7EkRe6&index=2\n",
    "\n",
    "La clase está buena aunque tiene bastante matemática. Es más que nada para que se entienda el concepto igualmente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación van a realizar experimentos con tres clasificadores básicos. Para cada uno van a tener que probar una serie de hiperparámetros. Les incluyo la documentación para que puedan leer qué es cada hiperparámetro que están probando. Luego de cada corrida, evaluan el clasificador con cuatro métricas: Accuracy Score, F1 micro, F1 macro y el promedio del F1 de la clase Favor con el F1 de la clase Against. La idea es que vayan cambiando los valores de un hiperparámetro dejando fijos el resto y vean cómo ese cambio impacta en las métricas. Finalmente, para cada clasificador escriban un pequeño informe planteando cuan sensible es cada parámetro respecto de cada métrica, por qué piensan que es así de sensible y cuales son los mejores valores que encontraron. Finalmente, elijan el clasificador que les parezca más adecuado para esta tarea y justifiquen su elección. Para ese clasificador que hayan elegido van a probar luego, una busqueda más exhaustiva de hiperparámetros usando Grid Search. Este procedimiento deben hacerlo **al menos** para **dos de los cuatro** datasets con los que venimos trabajando (aborto, aborto balanceado, cambio climático y feminismo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
       "      fit_intercept=True, max_iter=1000, n_iter=None, n_iter_no_change=5,\n",
       "      n_jobs=None, penalty='l1', random_state=0, shuffle=True, tol=0.001,\n",
       "      validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = abortion_train[\"Stance\"]\n",
    "y_test = abortion_test[\"Stance\"]\n",
    "\n",
    "\n",
    "# En principio, pueden utilizar el módulo que sigue, con los parámetros por defecto y los que definan a continuación:\n",
    "penalty =\n",
    "alpha = \n",
    "max_iter =\n",
    "tol =\n",
    "\n",
    "model = Perceptron(penalty = penalty, alpha = alpha, fit_intercept=True, max_iter = max_iter, tol = tol, shuffle=True, random_state=0, class_weight=None, warm_start=False)\n",
    "model.fit(VEC_train_abortion, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-90-2d7fb9e7cdf1>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-90-2d7fb9e7cdf1>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    f1_train_average = #TODO\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "y_pred_train =  model.predict(VEC_train_abortion)\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "f1_train_micro = f1_score(y_train, y_pred_train, average=\"micro\", labels=[\"NONE\", \"AGAINST\", \"FAVOR\"])\n",
    "f1_train_macro = f1_score(y_train, y_pred_train, average=\"macro\", labels=[\"NONE\", \"AGAINST\", \"FAVOR\"])\n",
    "f1_train = f1_score(y_train, y_pred_train, average=None, labels=[\"NONE\", \"AGAINST\", \"FAVOR\"])\n",
    "f1_train_average = #TODO\n",
    "\n",
    "print(\"Accuracy para conjunto de entrenamiento: %.2f\" % accuracy_train)\n",
    "print(\"F1 micro para conjunto de entrenamiento: %.2f\" % f1_train_micro)\n",
    "print(\"F1 macro para conjunto de entrenamiento: %.2f\" % f1_train_macro)\n",
    "print(\"F1 average para conjunto de entrenamiento: %.2f\" % f1_train_average)\n",
    "\n",
    "y_pred_test =  model.predict(VEC_test_abortion)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "f1_test_micro = f1_score(y_test, y_pred_test, average=\"micro\", labels=[\"NONE\", \"AGAINST\", \"FAVOR\"])\n",
    "f1_test_macro = f1_score(y_test, y_pred_test, average=\"macro\", labels=[\"NONE\", \"AGAINST\", \"FAVOR\"])\n",
    "f1_test = f1_score(y_test, y_pred_test, average=None, labels=[\"NONE\", \"AGAINST\", \"FAVOR\"])\n",
    "f1_test_average = #TODO\n",
    "\n",
    "print(\"Accuracy para conjunto de test: %.2f\" % accuracy_test)\n",
    "print(\"F1 micro para conjunto de test: %.2f\" % f1_test_micro)\n",
    "print(\"F1 macro para conjunto de test: %.2f\" % f1_test_macro)\n",
    "print(\"F1 average para conjunto de test: %.2f\" % f1_test_average)\n",
    "\n",
    "print(\"Exactitud del algoritmo para conjunto de test: %.2f\" % accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors =  # TODO: Cantidad de vecinos a tener en cuenta\n",
    "metric =  # TODO: Medida de distancia. Algunas opciones: cosine, euclidean, manhattan.\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=n_neighbors, metric=metric)\n",
    "model.fit(VEC_train_abortion, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train =  model.predict(VEC_train_abortion)\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "f1_train_micro = f1_score(y_train, y_pred_train, average=\"micro\", labels=[\"NONE\", \"AGAINST\", \"FAVOR\"])\n",
    "f1_train_macro = f1_score(y_train, y_pred_train, average=\"macro\", labels=[\"NONE\", \"AGAINST\", \"FAVOR\"])\n",
    "f1_train = f1_score(y_train, y_pred_train, average=None, labels=[\"NONE\", \"AGAINST\", \"FAVOR\"])\n",
    "f1_train_average = #TODO\n",
    "\n",
    "print(\"Accuracy para conjunto de entrenamiento: %.2f\" % accuracy_train)\n",
    "print(\"F1 micro para conjunto de entrenamiento: %.2f\" % f1_train_micro)\n",
    "print(\"F1 macro para conjunto de entrenamiento: %.2f\" % f1_train_macro)\n",
    "print(\"F1 average para conjunto de entrenamiento: %.2f\" % f1_train_average)\n",
    "\n",
    "y_pred_test =  model.predict(VEC_test_abortion)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "f1_test_micro = f1_score(y_test, y_pred_test, average=\"micro\", labels=[\"NONE\", \"AGAINST\", \"FAVOR\"])\n",
    "f1_test_macro = f1_score(y_test, y_pred_test, average=\"macro\", labels=[\"NONE\", \"AGAINST\", \"FAVOR\"])\n",
    "f1_test = f1_score(y_test, y_pred_test, average=None, labels=[\"NONE\", \"AGAINST\", \"FAVOR\"])\n",
    "f1_test_average = #TODO\n",
    "\n",
    "print(\"Accuracy para conjunto de test: %.2f\" % accuracy_test)\n",
    "print(\"F1 micro para conjunto de test: %.2f\" % f1_test_micro)\n",
    "print(\"F1 macro para conjunto de test: %.2f\" % f1_test_macro)\n",
    "print(\"F1 average para conjunto de test: %.2f\" % f1_test_average)\n",
    "\n",
    "print(\"Exactitud del algoritmo para conjunto de test: %.2f\" % accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penalty =   # TODO: Tipo de regularización: l1 (valor absoluto), l2 (cuadrados).\n",
    "alpha =   # TODO: Parámetro de regularización. También denominado como parámetro `lambda`. Debe ser mayor que 0.\n",
    "max_iter =   # TODO: Cantidad máxima de iteraciones del algoritmo.\n",
    "tol =   # TODO: Precisión del algoritmo (error mínimo entre una iteración y la siguiente).\n",
    "\n",
    "model = LogisticRegression(penalty=penalty, C=1./alpha, max_iter=max_iter, tol=tol)\n",
    "model.fit(VEC_train_abortion, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train =  model.predict(VEC_train_abortion)\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "f1_train_micro = f1_score(y_train, y_pred_train, average=\"micro\", labels=[\"NONE\", \"AGAINST\", \"FAVOR\"])\n",
    "f1_train_macro = f1_score(y_train, y_pred_train, average=\"macro\", labels=[\"NONE\", \"AGAINST\", \"FAVOR\"])\n",
    "f1_train = f1_score(y_train, y_pred_train, average=None, labels=[\"NONE\", \"AGAINST\", \"FAVOR\"])\n",
    "f1_train_average = #TODO\n",
    "\n",
    "print(\"Accuracy para conjunto de entrenamiento: %.2f\" % accuracy_train)\n",
    "print(\"F1 micro para conjunto de entrenamiento: %.2f\" % f1_train_micro)\n",
    "print(\"F1 macro para conjunto de entrenamiento: %.2f\" % f1_train_macro)\n",
    "print(\"F1 average para conjunto de entrenamiento: %.2f\" % f1_train_average)\n",
    "\n",
    "y_pred_test =  model.predict(VEC_test_abortion)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "f1_test_micro = f1_score(y_test, y_pred_test, average=\"micro\", labels=[\"NONE\", \"AGAINST\", \"FAVOR\"])\n",
    "f1_test_macro = f1_score(y_test, y_pred_test, average=\"macro\", labels=[\"NONE\", \"AGAINST\", \"FAVOR\"])\n",
    "f1_test = f1_score(y_test, y_pred_test, average=None, labels=[\"NONE\", \"AGAINST\", \"FAVOR\"])\n",
    "f1_test_average = #TODO\n",
    "\n",
    "print(\"Accuracy para conjunto de test: %.2f\" % accuracy_test)\n",
    "print(\"F1 micro para conjunto de test: %.2f\" % f1_test_micro)\n",
    "print(\"F1 macro para conjunto de test: %.2f\" % f1_test_macro)\n",
    "print(\"F1 average para conjunto de test: %.2f\" % f1_test_average)\n",
    "\n",
    "print(\"Exactitud del algoritmo para conjunto de test: %.2f\" % accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/damifur/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/damifur/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor conjunto de parámetros:\n",
      "{'C': 0.5, 'max_iter': 1000, 'tol': 0.005}\n",
      "\n",
      "\n",
      "Puntajes de la grilla:\n",
      "\n",
      "\n",
      "Reporte de clasificación para el mejor clasificador (sobre conjunto de evaluación):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     AGAINST       0.82      0.72      0.77       189\n",
      "       FAVOR       0.53      0.54      0.54        46\n",
      "        NONE       0.35      0.51      0.41        45\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       280\n",
      "   macro avg       0.57      0.59      0.57       280\n",
      "weighted avg       0.70      0.66      0.67       280\n",
      "\n",
      "\n",
      "================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Para la búsqueda de los mejores parámetros, por ejemplo de logistic regression, pueden usar:\n",
    "\n",
    "exploring_params = {\n",
    "        'C': [0.5, 1, 2, 5, 10, 20, 100, 200], # Inversa del coeficiente de regularización\n",
    "        'max_iter': [1000, 5000, 10000],  # Cantidad de iteraciones\n",
    "        'tol': [0.005, 0.002, 0.001, 0.0001]  # Precisión del algoritmo\n",
    "    }\n",
    "\n",
    "m = LogisticRegression()\n",
    "n_cross_val =  2 # Seleccionar folds\n",
    "scoring = \"f1_micro\"\n",
    "model = GridSearchCV(m, exploring_params, cv=n_cross_val, scoring=scoring)\n",
    "#    model.fit(X_train, y_train)\n",
    "    \n",
    "model.fit(VEC_train_abortion, y_train)\n",
    "\n",
    "print(\"Mejor conjunto de parámetros:\")\n",
    "print(model.best_params_, end=\"\\n\\n\")\n",
    "print()\n",
    "print(\"Puntajes de la grilla:\", end=\"\\n\\n\")\n",
    "means = model.cv_results_['mean_test_score']\n",
    "stds = model.cv_results_['std_test_score']\n",
    "print()\n",
    "print(\"Reporte de clasificación para el mejor clasificador (sobre conjunto de evaluación):\", end=\"\\n\\n\")\n",
    "y_true, y_pred = y_test, model.predict(VEC_test_abortion)\n",
    "print(classification_report(y_true, y_pred), end=\"\\n\\n\")\n",
    "\n",
    "print(\"================================================\", end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
